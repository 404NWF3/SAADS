# 按照 README.md 分步实现多智能体安全系统

**Session ID:** ses_3a5046113ffeM1i9gIx3HAMWsZ
**Created:** 2026/2/14 15:09:25
**Updated:** 2026/2/14 15:24:36

---

## User

我正要完成 @README.md 中描述的智能体，我应该如何一步步完成它？

---

## Assistant (Plan · claude-opus-4.6 · 126.8s)



我来仔细分析 README.md 中描述的系统架构，然后帮你制定一个分步实施计划。让我先了解当前项目的状态。

**Tool: task**

**Input:**
```json
{
  "description": "Explore project structure",
  "prompt": "Explore the codebase at E:\\@4C-2026\\SAADS thoroughly. I need to understand:\n1. The complete directory structure (all folders and files)\n2. Any existing code, configuration files, dependencies (package.json, requirements.txt, pyproject.toml, etc.)\n3. Any existing agent implementations or frameworks already in place\n4. Any data schemas, knowledge base files, or test scripts that exist\n5. Docker/container configuration files\n6. Any CI/CD pipeline files\n\nReturn a comprehensive overview of what already exists in the project, including the directory tree and key file contents summaries.",
  "subagent_type": "explore"
}
```

**Output:**
```
task_id: ses_3a5043d32ffeavGx078a91IB6M (for resuming to continue this task if needed)

<task_result>
I now have a complete picture. Here is the comprehensive overview:

---

## Comprehensive Codebase Overview: SAADS

**Repository:** `https://github.com/404NWF3/SAADS.git` (branch: `main`, 13 commits)
**Full Name:** (Chinese) "Multi-Agent AI System Situational Awareness & Automated Defense System"
**Acronym:** S.A.A.D.S.

---

### 1. Complete Directory Tree

```
E:\@4C-2026\SAADS\
|
|-- .env.example                    # Environment variable template (API keys)
|-- .gitignore                      # Ignores .env, .claude/, .vscode/, .venv/, __pycache__
|-- main.py                         # Python entry point (STUB - prints "Hello from saada!")
|-- pyproject.toml                  # Python project config (uv-managed)
|-- requirements.txt                # Full pinned Python deps (578 lines, auto-generated by uv)
|-- uv.lock                         # uv lockfile
|-- README.md                       # Comprehensive architecture documentation (Chinese)
|-- demo.html                       # Standalone HTML demo/simulation page
|
|-- .venv/                          # Python virtual environment (installed)
|
|-- assets/                         # Architecture diagram images
|   |-- 01_cyber_defense_pipeline.png
|   |-- 01_cyber_defense_pipeline.svg
|   |-- 02_Intelligence-Collection-Module.png
|   |-- 02_Intelligence-Collection-Module.svg
|   |-- 03_Red-team-Orchestrator.svg
|
|-- docs/
|   |-- diagrams/
|       |-- 01_cyber_defense_pipeline.mmd       # Mermaid: high-level pipeline diagram
|       |-- 02_Intelligence-Collection-Module.mmd # Mermaid: WP1-1 intel collection
|       |-- 03_Red-team-Orchestrator.mmd         # Mermaid: WP1-2 red team orchestrator
|       |-- core-architecture.mmd                # Mermaid: full 4-agent architecture
|
|-- web/                            # React + TypeScript frontend application
    |-- .gitignore
    |-- eslint.config.js
    |-- index.html                  # HTML shell
    |-- package.json                # NPM dependencies
    |-- package-lock.json
    |-- tsconfig.json
    |-- tsconfig.app.json
    |-- tsconfig.node.json
    |-- vite.config.ts              # Vite bundler configuration
    |
    |-- src/
        |-- main.tsx                # React entry point
        |-- App.tsx                 # Root router + Ant Design ConfigProvider
        |-- index.css               # Global CSS + Ant Design overrides (620 lines)
        |
        |-- styles/
        |   |-- anthropic-theme.css  # Full design system variables (colors, fonts, spacing)
        |
        |-- types/
        |   |-- index.ts            # ALL TypeScript data interfaces (229 lines)
        |
        |-- services/
        |   |-- api.ts              # API service layer (currently returns mock data)
        |
        |-- mock/
        |   |-- data.ts             # Comprehensive mock data (592 lines)
        |
        |-- components/
        |   |-- common/
        |   |   |-- index.ts             # Barrel exports
        |   |   |-- AgentArchitecture.tsx + .css
        |   |   |-- DataFlowDiagram.tsx + .css
        |   |   |-- GlowCard.tsx
        |   |   |-- LogStream.tsx
        |   |   |-- ParticleFlowDiagram.tsx + .css
        |   |   |-- StatCard.tsx
        |   |   |-- TechBadge.tsx + .css
        |   |   |-- TypewriterText.tsx
        |   |
        |   |-- layout/
        |       |-- index.ts
        |       |-- DashboardLayout.tsx  # Sidebar + header + outlet layout
        |
        |-- pages/
            |-- home/
            |   |-- index.tsx           # Landing/marketing page (944 lines)
            |   |-- components/
            |       |-- index.ts
            |       |-- FourAgentSystem.tsx + .css   # 4-agent visualization component
            |       |-- AttackShowcase.tsx + .css     # Live attack simulation demo
            |       |-- AgentShowcase.tsx + .css
            |
            |-- dashboard/
                |-- index.tsx           # Dashboard overview with charts (503 lines)
                |-- wp1-1/index.tsx     # Intel collection dashboard (attack pool table)
                |-- wp1-2/index.tsx     # Red team dashboard (vuln reports table)
                |-- wp1-3/index.tsx     # Sandbox dashboard (placeholder/planned)
                |-- wp1-4/index.tsx     # IDS dashboard (placeholder/planned)
```

---

### 2. Dependencies & Configuration

#### Python Backend (`pyproject.toml`)
- **Project name:** SAADA, v0.1.0
- **Python:** >=3.10
- **Package manager:** `uv` (lockfile present, venv installed)
- **Core dependencies:**
  - `google-adk >= 1.22.1` -- Google Agent Development Kit (major dependency, pulls in FastAPI, uvicorn, SQLAlchemy, MCP, GCP clients, OpenTelemetry, etc.)
  - `langchain >= 0.1.0` -- LangChain orchestration framework
  - `langchain-google-genai >= 4.2.0` -- LangChain + Google Gemini integration
  - `langchain-openai >= 0.0.5` -- LangChain + OpenAI integration
  - `python-dotenv >= 1.0.0` -- Environment variable management

- **Transitive deps (notable):** LangGraph, LangGraph-Prebuilt, MCP (Model Context Protocol), FastAPI, uvicorn, Pydantic v2, google-genai, OpenAI SDK, OpenTelemetry stack, PyArrow, SQLAlchemy, Google Cloud suite (BigQuery, Spanner, Pub/Sub, Secret Manager, Speech, Storage, etc.)

#### Environment Variables (`.env.example`)
- `GOOGLE_API_KEY` -- for google-adk and langchain-google-genai
- `OPENAI_API_KEY` -- for langchain-openai
- `GOOGLE_CLOUD_PROJECT` (optional)

#### Frontend (`web/package.json`)
- **Framework:** React 19.2 + TypeScript 5.9 + Vite 7.2
- **UI Library:** Ant Design v6.2.3 + @ant-design/charts v2.6.7 + @ant-design/icons v6.1.0
- **Routing:** react-router-dom v7.13
- **Date:** dayjs v1.11
- **Linting:** ESLint 9.39 + typescript-eslint + react-hooks + react-refresh plugins

---

### 3. Agent Implementations & Frameworks

#### Current State: **Design phase, no functional agent code exists yet**

The `main.py` is a stub:
```python
def main():
    print("Hello from saada!")
```

**However, the architecture is exhaustively documented** in the README and Mermaid diagrams. The system is designed as four cooperating intelligent agents:

| Agent | Code | Role | Internal Architecture |
|-------|------|------|-----------------------|
| **WP1-1** Intel Collection | Not implemented | Threat intelligence gathering from CVE, arXiv, GitHub, dark web | Supervisor pattern |
| **WP1-2** Penetration Testing | Not implemented | Generates attack scripts/test plans from intel | Supervisor pattern |
| **WP1-3** Sandbox Simulation | Not implemented | Clones user systems, executes tests in Docker, collects data | Pipeline pattern |
| **WP1-4** Intrusion Detection | Not implemented | Trains ML models for anomaly detection (ADBench, GAN, etc.) | Pipeline pattern |

**Planned frameworks (from dependencies):**
- **LangGraph** for agent orchestration (state machines, multi-agent workflows)
- **Google ADK** (Agent Development Kit) for agent runtime
- **MCP** (Model Context Protocol) for tool integration
- **LangChain** for LLM integration layer
- Communication via **Central Knowledge Store** (file-based JSON, evolving to vector DB)

**Planned agent internal components** (from Mermaid diagrams and README):
- WP1-1: Intel Supervisor, Web Crawler Agent, Paper Analyzer Agent, Dark Web Agent, Standardizer Agent
- WP1-2: Red Team Orchestrator, Prompt Injection Agent, Jailbreak Agent, Info Leakage Agent, Multimodal Attack Agent, Judge Agent
- WP1-3: Env Manager, Payload Mutator, Sandboxed Executor, Data Collector, Labeler
- WP1-4: Data Loader, Meta-Learning Selector, Trainer, Evaluator, Deployer

---

### 4. Data Schemas, Knowledge Base Files & Test Scripts

#### TypeScript Data Schemas (`web/src/types/index.ts` -- 229 lines)
Comprehensive type definitions exist for:
- **AttackEntry** (STIX 2.1 compatible) -- `attack_id`, `category` (prompt_injection | jailbreak | info_leakage | multimodal | dos | agent_hijack), `source`, `attack_template`, `mitre_mapping`, `metadata`
- **VulnReport** -- `vuln_id`, `target_application`, `vulnerability` (CVSS score/vector), `reproduction`, `executable_script`, `status`
- **LabeledSample** -- `sample_id`, `label` (malicious | benign), `model_interaction` (conversation turns), `network_trace` (PCAP), `system_log`, `features`
- **TrainedModel** -- `model_id`, `model_type`, `metrics` (F1, AUC, precision, recall, FPR, FNR), `feature_importance`, `status`
- **Dashboard stats types** -- AttackPoolStats, VulnReportStats, SandboxStats, IDSStats, PipelineStatus

#### Mock Data (`web/src/mock/data.ts` -- 592 lines)
Rich mock datasets exist:
- **6 attack entries** covering: context window overflow injection, DAN 15.0 jailbreak, system prompt extraction, adversarial image injection, RAG document poisoning, Base64 encoding bypass
- **5 vulnerability reports** with full CVSS scoring, attack steps, remediation suggestions
- **Statistical mock data** for all 4 subsystems including OWASP LLM Top 10 coverage percentages
- **Pipeline status** mock showing WP1-1 and WP1-2 as "completed", WP1-3 and WP1-4 as "idle"

#### Knowledge Base Files
- **No actual knowledge base files exist on disk** (no `attack_pool/`, `vuln_reports/`, `labeled_data/`, `models/` directories)
- These are planned directories referenced extensively in the architecture docs

#### Test Scripts
- **No test scripts exist** -- no `tests/` directory, no `*test*` files found anywhere in the project

---

### 5. Docker / Container Configuration

**None.** No `Dockerfile`, `docker-compose.yml`, `.dockerignore`, or any container configuration files exist. Docker/K8s is listed in the tech stack and planned for WP1-3 sandbox isolation, but nothing has been implemented.

---

### 6. CI/CD Pipeline Files

**None.** No `.github/` directory, no `.yml`/`.yaml` files, no `Jenkinsfile`, no `Makefile`, no CI/CD configuration of any kind exists.

---

### 7. Summary Assessment

| Area | Status |
|------|--------|
| **Architecture Design** | COMPLETE -- Extensively documented in README (220 lines), 4 Mermaid diagrams, detailed agent/subsystem specifications |
| **Python Backend (Agents)** | NOT STARTED -- Only a hello-world `main.py` stub. Dependencies installed (LangGraph, Google ADK, LangChain, OpenAI) but no agent code |
| **Frontend Web App** | SUBSTANTIALLY COMPLETE -- Full React/TypeScript/Vite app with: landing page, dashboard overview, WP1-1 and WP1-2 detail pages with data tables/charts, WP1-3 and WP1-4 placeholder pages, complete design system, extensive mock data, API service layer ready for backend connection |
| **Data Schemas** | COMPLETE (frontend) -- Full TypeScript type definitions for all data entities (STIX, CVSS, attack entries, vuln reports, labeled samples, trained models) |
| **Mock Data** | COMPLETE -- Realistic mock datasets for attacks, vulnerabilities, and statistics |
| **Demo** | COMPLETE -- Standalone `demo.html` with a 4-stage interactive simulation |
| **Diagrams** | COMPLETE -- 4 Mermaid diagrams (pipeline, intel module, red team, core architecture) + exported SVG/PNG assets |
| **Docker/Infra** | NOT STARTED |
| **CI/CD** | NOT STARTED |
| **Tests** | NOT STARTED |
| **Knowledge Base** | NOT STARTED -- No actual data files (attack_pool, vuln_reports, etc.) |

**In essence:** The project has a thorough architectural blueprint and a polished presentation/dashboard frontend, but the core backend agent implementation -- the actual multi-agent AI security system -- has not been built yet. The Python side is essentially a blank canvas with the right dependencies installed and ready to go.
</task_result>
```

---

## Assistant (Plan · claude-opus-4.6 · 26.5s)

很好，我现在对项目全貌有了清晰的理解。让我总结当前状态并给出分步实施计划。

## 当前项目状态

| 部分 | 状态 |
|------|------|
| 架构设计 & 文档 | **完成** |
| 前端仪表盘 | **基本完成**（React + Ant Design，含 mock 数据） |
| 数据类型定义 | **完成**（TypeScript 侧） |
| **Python 后端（智能体核心）** | **未开始** — 仅有 `main.py` 占位 |
| 知识库 / 数据目录 | **未创建** |
| Docker / 基础设施 | **未开始** |
| 测试 | **未开始** |

你的核心框架依赖已安装好：**LangGraph**、**Google ADK**、**LangChain**、**OpenAI SDK**。

---

在制定具体计划前，我有几个关键问题需要确认：

**Tool: question**

**Input:**
```json
{
  "questions": "[{\"question\":\"你打算用哪个框架来实现智能体的核心编排逻辑？你已安装了 LangGraph 和 Google ADK 两套框架。\",\"header\":\"智能体框架选择\",\"options\":[{\"label\":\"LangGraph (推荐)\",\"description\":\"LangGraph 更成熟，社区资源丰富，原生支持 Supervisor/Pipeline 等多种 Agent 架构模式，与 LangChain 生态无缝集成\"},{\"label\":\"Google ADK\",\"description\":\"Google Agent Development Kit，与 Google Cloud 深度集成，适合使用 Gemini 模型的场景\"},{\"label\":\"两者结合\",\"description\":\"核心编排用 LangGraph，部分工具调用通过 Google ADK 接入\"}]},{\"question\":\"你想从哪个智能体开始实现？README 中建议第一阶段主攻大模型安全（提示词注入、越狱等）。\",\"header\":\"实现优先级\",\"options\":[{\"label\":\"WP1-1 情报采集 (推荐)\",\"description\":\"从数据源头开始，先有情报才能驱动后续流程。可以先实现简单的爬虫 + 标准化，构建 attack_pool\"},{\"label\":\"WP1-2 渗透测试\",\"description\":\"先实现测试方案生成能力，用手动构造的情报数据作为输入\"},{\"label\":\"WP1-1 + WP1-2 并行\",\"description\":\"通用层两个智能体同时推进，用共享的 JSON 知识库解耦\"}]},{\"question\":\"知识库的初始实现方式？README 提到\"先用文件系统 + JSON 跑通\"。\",\"header\":\"知识库实现\",\"options\":[{\"label\":\"文件系统 + JSON (推荐)\",\"description\":\"遵循 README 的渐进式原则，先用 JSON 文件存储 attack_pool、test_scripts 等数据，快速跑通流程\"},{\"label\":\"SQLite + JSON\",\"description\":\"用 SQLite 做结构化索引，JSON 存储详细内容，兼顾查询效率和灵活性\"},{\"label\":\"直接上向量数据库\",\"description\":\"使用 ChromaDB/FAISS 等，一步到位但初期复杂度高\"}]},{\"question\":\"你对实现深度的期望是什么？比如 WP1-1 的暗网爬取（Dark Web Agent）在初始阶段可能不现实。\",\"header\":\"实现范围\",\"options\":[{\"label\":\"MVP 核心流程 (推荐)\",\"description\":\"每个智能体只实现最核心的 1-2 个 Agent，先跑通端到端流程（情报采集→方案生成→沙盒执行→模型训练）\"},{\"label\":\"WP1-1 + WP1-2 完整实现\",\"description\":\"先把通用层两个智能体做到较完整的程度，包含多个子 Agent\"},{\"label\":\"全部四个智能体完整实现\",\"description\":\"一次性实现所有子系统的所有功能（工作量巨大）\"}]}]"
}
```

**Error:**
```
Error: The question tool was called with invalid arguments: [
  {
    "expected": "array",
    "code": "invalid_type",
    "path": [
      "questions"
    ],
    "message": "Invalid input: expected array, received string"
  }
].
Please rewrite the input so it satisfies the expected schema.
```

---

## Assistant (Plan · claude-opus-4.6 · 7.3s)

**Tool: question**

**Input:**
```json
{
  "questions": [
    {
      "question": "你打算用哪个框架来实现智能体的核心编排逻辑？你已安装了 LangGraph 和 Google ADK 两套框架。",
      "header": "智能体框架选择",
      "options": [
        {
          "label": "LangGraph (推荐)",
          "description": "LangGraph 更成熟，社区资源丰富，原生支持 Supervisor/Pipeline 等多种 Agent 架构模式，与 LangChain 生态无缝集成"
        },
        {
          "label": "Google ADK",
          "description": "Google Agent Development Kit，与 Google Cloud 深度集成，适合使用 Gemini 模型的场景"
        },
        {
          "label": "两者结合",
          "description": "核心编排用 LangGraph，部分工具调用通过 Google ADK 接入"
        }
      ]
    }
  ]
}
```

**Output:**
```
User has answered your questions: "你打算用哪个框架来实现智能体的核心编排逻辑？你已安装了 LangGraph 和 Google ADK 两套框架。"="LangGraph (推荐)". You can now continue with the user's answers in mind.
```

---

## Assistant (Plan · claude-opus-4.6 · 422.8s)

**Tool: question**

**Input:**
```json
{
  "questions": [
    {
      "header": "实现优先级",
      "options": [
        {
          "description": "从数据源头开始，先有情报才能驱动后续流程。可以先实现简单的爬虫 + 标准化，构建 attack_pool",
          "label": "WP1-1 情报采集 (推荐)"
        },
        {
          "description": "先实现测试方案生成能力，用手动构造的情报数据作为输入",
          "label": "WP1-2 渗透测试"
        },
        {
          "description": "通用层两个智能体同时推进，用共享的 JSON 知识库解耦",
          "label": "WP1-1 + WP1-2 并行"
        }
      ],
      "question": "你想从哪个智能体开始实现？README 中建议第一阶段主攻大模型安全。"
    }
  ]
}
```

**Output:**
```
User has answered your questions: "你想从哪个智能体开始实现？README 中建议第一阶段主攻大模型安全。"="WP1-1 + WP1-2 并行". You can now continue with the user's answers in mind.
```

---

## Assistant (Plan · claude-opus-4.6 · 114.7s)

**Tool: question**

**Input:**
```json
{
  "questions": [
    {
      "header": "知识库实现",
      "options": [
        {
          "description": "遵循 README 的渐进式原则，先用 JSON 文件存储 attack_pool、test_scripts 等数据，快速跑通流程",
          "label": "文件系统 + JSON (推荐)"
        },
        {
          "description": "用 SQLite 做结构化索引，JSON 存储详细内容，兼顾查询效率和灵活性",
          "label": "SQLite + JSON"
        },
        {
          "description": "使用 ChromaDB/FAISS 等，一步到位但初期复杂度高",
          "label": "直接上向量数据库"
        }
      ],
      "question": "知识库的初始实现方式？README 提到“先用文件系统 + JSON 跑通”。"
    }
  ]
}
```

**Output:**
```
User has answered your questions: "知识库的初始实现方式？README 提到“先用文件系统 + JSON 跑通”。"="文件系统 + JSON (推荐)". You can now continue with the user's answers in mind.
```

---

## Assistant (Plan · claude-opus-4.6 · 29.1s)

**Tool: question**

**Input:**
```json
{
  "questions": [
    {
      "header": "实现范围",
      "options": [
        {
          "description": "每个智能体只实现最核心的 1-2 个 Agent，先跑通端到端流程（情报采集→方案生成→沙盒执行→模型训练）",
          "label": "MVP 核心流程 (推荐)"
        },
        {
          "description": "先把通用层两个智能体做到较完整的程度，包含多个子 Agent",
          "label": "WP1-1 + WP1-2 完整实现"
        },
        {
          "description": "一次性实现所有子系统的所有功能（工作量巨大）",
          "label": "全部四个智能体完整实现"
        }
      ],
      "question": "你对实现深度的期望是什么？比如 WP1-1 的暗网爬取（Dark Web Agent）在初始阶段可能不现实。"
    }
  ]
}
```

**Output:**
```
User has answered your questions: "你对实现深度的期望是什么？比如 WP1-1 的暗网爬取（Dark Web Agent）在初始阶段可能不现实。"="WP1-1 + WP1-2 完整实现". You can now continue with the user's answers in mind.
```

---

## Assistant (Plan · claude-opus-4.6 · 6.7s)

好的，基于你的选择，我来制定详细的分步实施计划。让我再确认一下现有的 Python 数据模型定义和 Mermaid 图的细节，以便计划更精确。

**Tool: read**

**Input:**
```json
{
  "filePath": "E:\\@4C-2026\\SAADS\\web\\src\\types\\index.ts"
}
```

**Output:**
```
<path>E:\@4C-2026\SAADS\web\src\types\index.ts</path>
<type>file</type>
<content>1: // ==================== 攻击池数据类型 (STIX 2.1 兼容) ====================
2: export interface AttackSource {
3:   type: 'arxiv' | 'cve' | 'nvd' | 'blog' | 'github' | 'darkweb' | 'threat_api';
4:   url: string;
5:   crawl_time: string;
6:   confidence: 'high' | 'medium' | 'low';
7: }
8: 
9: export interface AttackTemplate {
10:   name: string;
11:   description: string;
12:   payload_template: string;
13:   variables: Record<string, string>;
14:   modality: 'text' | 'image' | 'audio';
15:   mutation_hints: string[];
16: }
17: 
18: export interface MitreMapping {
19:   tactic: string;
20:   technique: string;
21: }
22: 
23: export interface AttackMetadata {
24:   severity_estimate: 'critical' | 'high' | 'medium' | 'low';
25:   target_type: string[];
26:   defense_bypass: string[];
27:   effectiveness: number | null;
28:   last_tested: string | null;
29: }
30: 
31: export interface AttackEntry {
32:   attack_id: string;
33:   category: 'prompt_injection' | 'jailbreak' | 'info_leakage' | 'multimodal' | 'dos' | 'agent_hijack';
34:   subcategory: string;
35:   stix_type: string;
36:   source: AttackSource;
37:   attack_template: AttackTemplate;
38:   mitre_mapping: MitreMapping;
39:   metadata: AttackMetadata;
40:   status: 'active' | 'tested' | 'deprecated';
41: }
42: 
43: // ==================== 漏洞报告数据类型 ====================
44: export interface TargetApplication {
45:   name: string;
46:   api_endpoint: string;
47:   model: string;
48:   has_system_prompt: boolean;
49:   has_tools: boolean;
50:   has_rag: boolean;
51: }
52: 
53: export interface AttackStep {
54:   step: number;
55:   action: string;
56:   input: string;
57:   output: string;
58: }
59: 
60: export interface AttackVector {
61:   successful_payload: string;
62:   modality: 'text' | 'image' | 'audio';
63:   attack_steps: AttackStep[];
64:   success_indicator: string;
65: }
66: 
67: export interface Remediation {
68:   suggestion: string;
69:   priority: 'immediate' | 'high' | 'medium' | 'low';
70:   references: string[];
71: }
72: 
73: export interface Vulnerability {
74:   type: string;
75:   subtype: string;
76:   severity: 'critical' | 'high' | 'medium' | 'low';
77:   cvss_score: number;
78:   cvss_vector: string;
79:   description: string;
80:   attack_vector: AttackVector;
81:   remediation: Remediation;
82: }
83: 
84: export interface Reproduction {
85:   deterministic: boolean;
86:   success_rate: string;
87:   environment_requirements: string;
88:   mutation_variants_tested: number;
89: }
90: 
91: export interface ExecutableScript {
92:   language: string;
93:   path: string;
94:   description: string;
95: }
96: 
97: export interface VulnReport {
98:   vuln_id: string;
99:   source_attack_id: string;
100:   target_application: TargetApplication;
101:   vulnerability: Vulnerability;
102:   reproduction: Reproduction;
103:   executable_script: ExecutableScript;
104:   timestamp: string;
105:   status: 'confirmed' | 'pending' | 'rejected';
106: }
107: 
108: // ==================== 标注数据类型 ====================
109: export interface ConversationTurn {
110:   role: 'user' | 'assistant';
111:   content: string;
112:   is_attack_turn?: boolean;
113:   attack_technique?: string;
114:   is_compromised?: boolean;
115:   compromise_type?: string;
116: }
117: 
118: export interface ModelInteraction {
119:   conversation: ConversationTurn[];
120: }
121: 
122: export interface NetworkTrace {
123:   pcap_path: string;
124:   summary: {
125:     total_packets: number;
126:     protocols: string[];
127:     payload_size_bytes: number;
128:   };
129: }
130: 
131: export interface SystemLog {
132:   log_path: string;
133:   anomaly_indicators: string[];
134: }
135: 
136: export interface Features {
137:   input_length: number;
138:   contains_encoded_content: boolean;
139:   language_switch_count: number;
140:   instruction_override_patterns: number;
141:   response_time_ms: number;
142:   token_count_input: number;
143:   token_count_output: number;
144: }
145: 
146: export interface LabeledSample {
147:   sample_id: string;
148:   source_vuln_id: string;
149:   label: 'malicious' | 'benign';
150:   attack_type: string;
151:   model_interaction: ModelInteraction;
152:   network_trace: NetworkTrace;
153:   system_log: SystemLog;
154:   features: Features;
155:   generation_method: 'mutation' | 'original' | 'synthetic';
156:   mutation_from?: string;
157: }
158: 
159: // ==================== 模型训练数据类型 ====================
160: export interface ModelMetrics {
161:   f1_score: number;
162:   auc: number;
163:   precision: number;
164:   recall: number;
165:   false_positive_rate: number;
166:   false_negative_rate: number;
167: }
168: 
169: export interface TrainedModel {
170:   model_id: string;
171:   model_type: 'random_forest' | 'xgboost' | 'cnn' | 'transformer' | 'deeplog' | 'gan';
172:   version: string;
173:   trained_at: string;
174:   metrics: ModelMetrics;
175:   feature_importance: Record<string, number>;
176:   status: 'training' | 'evaluating' | 'deployed' | 'archived';
177: }
178: 
179: // ==================== Dashboard 统计数据类型 ====================
180: export interface AttackPoolStats {
181:   total: number;
182:   by_category: Record<string, number>;
183:   by_source: Record<string, number>;
184:   by_severity: Record<string, number>;
185:   recent_trend: { date: string; count: number }[];
186: }
187: 
188: export interface VulnReportStats {
189:   total: number;
190:   confirmed: number;
191:   pending: number;
192:   rejected: number;
193:   by_severity: Record<string, number>;
194:   cvss_distribution: { range: string; count: number }[];
195:   owasp_coverage: { category: string; covered: number; total: number }[];
196: }
197: 
198: export interface SandboxStats {
199:   total_samples: number;
200:   malicious_samples: number;
201:   benign_samples: number;
202:   pcap_files: number;
203:   total_size_mb: number;
204: }
205: 
206: export interface IDSStats {
207:   models_trained: number;
208:   best_model: string;
209:   best_f1: number;
210:   deployed_models: number;
211: }
212: 
213: // ==================== Pipeline 状态类型 ====================
214: export interface PipelineStage {
215:   name: string;
216:   status: 'idle' | 'running' | 'completed' | 'failed';
217:   progress: number;
218:   started_at?: string;
219:   completed_at?: string;
220:   error?: string;
221: }
222: 
223: export interface PipelineStatus {
224:   current_stage: string;
225:   stages: PipelineStage[];
226:   last_run: string;
227:   total_runs: number;
228: }
229: 

(End of file - total 229 lines)
</content>
```

**Tool: read**

**Input:**
```json
{
  "filePath": "E:\\@4C-2026\\SAADS\\docs\\diagrams\\02_Intelligence-Collection-Module.mmd"
}
```

**Output:**
```
<path>E:\@4C-2026\SAADS\docs\diagrams\02_Intelligence-Collection-Module.mmd</path>
<type>file</type>
<content>1: graph TD
2:     subgraph Intelligence Collection Module
3:         Supervisor["Intel Supervisor<br>分析覆盖率, 决定爬取策略"]
4: 
5:         subgraph Collection Agents
6:             direction LR
7:             Crawler["<b>Web Crawler Agent</b><br>- CVE/NVD<br>- MITRE<br>- GitHub<br>- HuggingFace"]
8:             Paper["<b>Paper Analyzer Agent</b><br>- arXiv<br>- 安全报告<br>- PoC代码"]
9:             DarkWeb["<b>Dark Web Agent</b><br>- 论坛<br>- TG群组"]
10:         end
11: 
12:         subgraph Processing Agent
13:              Standardizer["<b>Standardizer Agent</b><br>- 去重<br>- STIX 2.1<br>- 写入知识库"]
14:         end
15: 
16:         %% Control Flow: Supervisor tasks the collection agents
17:         Supervisor -- "下达采集策略" --> Crawler
18:         Supervisor -- "下达采集策略" --> Paper
19:         Supervisor -- "下达采集策略" --> DarkWeb
20:         
21:         %% Data Flow: Raw data is sent to the Standardizer
22:         Crawler -- "原始数据" --> Standardizer
23:         Paper -- "原始数据" --> Standardizer
24:         DarkWeb -- "原始数据" --> Standardizer
25: 
26:         %% Feedback Loop: Standardized data is reported back to the Supervisor
27:         Standardizer -- "标准化结果反馈" --> Supervisor
28:     end
29: 
30: 
31:     %% --- Styling Section ---
32:     classDef supervisor fill:#E1959A,color:#000000,stroke:#000000,stroke-width:2px
33:     classDef agent fill:#639DD0,color:#ffffff,stroke:#000000,stroke-width:2px
34:     classDef processor fill:#FFC79A,color:#000000,stroke:#000000,stroke-width:2px
35: 
36:     %% Applying Styles to Nodes
37:     class Supervisor supervisor
38:     class Crawler,Paper,DarkWeb agent
39:     class Standardizer processor

(End of file - total 39 lines)
</content>
```

**Tool: read**

**Input:**
```json
{
  "filePath": "E:\\@4C-2026\\SAADS\\docs\\diagrams\\03_Red-team-Orchestrator.mmd"
}
```

**Output:**
```
<path>E:\@4C-2026\SAADS\docs\diagrams\03_Red-team-Orchestrator.mmd</path>
<type>file</type>
<content>1: graph TD
2:     subgraph Red Team Simulation Module
3:         Orchestrator["<b>Red Team Orchestrator</b><br>从 attack_pool 取攻击, 分派给专家"]
4: 
5:         subgraph Attack Agents
6:             direction LR
7:             PIA["<b>Prompt Injection Agent</b><br>- 直接/间接注入<br>- 上下文操纵<br>- 指令覆盖"]
8:             JA["<b>Jailbreak Agent</b><br>- DAN/越狱<br>- 角色扮演<br>- 编码绕过"]
9:             ILA["<b>Info Leakage Agent</b><br>- 系统提示词提取<br>- 训练数据探测<br>- 配置信息泄露"]
10:             MAA["<b>Multimodal Attack Agent</b><br>- 图像对抗样本<br>- 音频攻击<br>- 跨模态注入"]
11:         end
12: 
13:         subgraph Evaluation Agent
14:             Judge["<b>Judge Agent (攻击评估者)</b><br>- 判定攻击是否成功<br>- CVSS 评分<br>- 生成修复建议"]
15:         end
16: 
17:         %% Control Flow: Orchestrator assigns tasks to Attack Agents
18:         Orchestrator -- "分派攻击任务" --> PIA
19:         Orchestrator -- "分派攻击任务" --> JA
20:         Orchestrator -- "分派攻击任务" --> ILA
21:         Orchestrator -- "分派攻击任务" --> MAA
22: 
23:         %% Data Flow: Attack results are sent to the Judge Agent
24:         PIA -- "攻击结果" --> Judge
25:         JA -- "攻击结果" --> Judge
26:         ILA -- "攻击结果" --> Judge
27:         MAA -- "攻击结果" --> Judge
28:     end
29: 
30:     %% --- Styling Section ---
31:     classDef orchestrator fill:#E1959A,color:#000000,stroke:#000000,stroke-width:2px
32:     classDef attackAgent fill:#639DD0,color:#ffffff,stroke:#000000,stroke-width:2px
33:     classDef judgeAgent fill:#FFC79A,color:#000000,stroke:#000000,stroke-width:2px
34: 
35:     %% Applying Styles to Nodes
36:     class Orchestrator orchestrator
37:     class PIA,JA,ILA,MAA attackAgent
38:     class Judge judgeAgent

(End of file - total 38 lines)
</content>
```

---

## Assistant (Plan · claude-opus-4.6 · 3.9s)

**Tool: read**

**Input:**
```json
{
  "filePath": "E:\\@4C-2026\\SAADS\\pyproject.toml"
}
```

**Output:**
```
<path>E:\@4C-2026\SAADS\pyproject.toml</path>
<type>file</type>
<content>1: [project]
2: name = "SAADA"
3: version = "0.1.0"
4: description = "Add your description here"
5: readme = "README.md"
6: requires-python = ">=3.10"
7: dependencies = [
8:     "google-adk>=1.22.1",
9:     "langchain>=0.1.0",
10:     "langchain-google-genai>=4.2.0",
11:     "langchain-openai>=0.0.5",
12:     "python-dotenv>=1.0.0",
13: ]
14: 
15: 

(End of file - total 15 lines)
</content>
```

**Tool: read**

**Input:**
```json
{
  "filePath": "E:\\@4C-2026\\SAADS\\.env.example"
}
```

**Output:**
```
<path>E:\@4C-2026\SAADS\.env.example</path>
<type>file</type>
<content>1: # Google AI API 密钥 (用于 google-adk 和 langchain-google-genai)
2: GOOGLE_API_KEY=your_google_api_key_here
3: 
4: # OpenAI API 密钥 (用于 langchain-openai)
5: OPENAI_API_KEY=your_openai_api_key_here
6: 
7: # 可选：Google Cloud 项目配置
8: # GOOGLE_CLOUD_PROJECT=your_project_id
9: 

(End of file - total 9 lines)
</content>
```

**Tool: read**

**Input:**
```json
{
  "filePath": "E:\\@4C-2026\\SAADS\\main.py"
}
```

**Output:**
```
<path>E:\@4C-2026\SAADS\main.py</path>
<type>file</type>
<content>1: def main():
2:     print("Hello from saada!")
3: 
4: 
5: if __name__ == "__main__":
6:     main()
7: 

(End of file - total 7 lines)
</content>
```

---

## Assistant (Plan · claude-opus-4.6 · 94.2s)

现在我有了完整的上下文，以下是基于你的选择的详细分步实施计划：

---

## 分步实施计划

根据你的选择：**LangGraph** 框架 / **WP1-1 + WP1-2 并行** / **文件系统 + JSON** / **通用层完整实现**

---

### 阶段 0：项目基础设施搭建

| 步骤 | 内容 | 详情 |
|------|------|------|
| 0.1 | **Python 项目结构** | 创建标准 Python 包结构：`saads/` 包，按子系统划分模块 |
| 0.2 | **数据模型 (Pydantic)** | 将前端 TypeScript 类型定义 (`web/src/types/index.ts`) 镜像为 Python Pydantic v2 模型（`AttackEntry`, `VulnReport` 等），确保前后端 schema 一致 |
| 0.3 | **知识库层** | 实现文件系统 + JSON 的知识库读写接口：`attack_pool/`、`test_scripts/`、`vuln_reports/` 目录结构，提供 CRUD 操作的抽象层 |
| 0.4 | **配置管理** | 统一的配置加载（.env + 环境变量）、LLM 初始化工厂（支持 Gemini / OpenAI 切换） |
| 0.5 | **补充依赖** | 添加 `langgraph`、`httpx`、`beautifulsoup4`、`pydantic` 等缺失的直接依赖 |

**目标产出的目录结构：**

```
saads/
├── __init__.py
├── config.py                    # 配置管理、LLM 工厂
├── models/                      # Pydantic 数据模型
│   ├── __init__.py
│   ├── attack.py                # AttackEntry, AttackSource, AttackTemplate...
│   ├── vuln_report.py           # VulnReport, Vulnerability...
│   ├── labeled_sample.py        # LabeledSample, Features...
│   └── trained_model.py         # TrainedModel, ModelMetrics...
├── knowledge_base/              # 知识库读写抽象层
│   ├── __init__.py
│   ├── base.py                  # 基类接口
│   ├── attack_pool.py           # attack_pool CRUD
│   └── test_scripts.py          # test_scripts CRUD
├── agents/
│   ├── __init__.py
│   ├── wp1_1/                   # 情报采集智能体
│   │   └── ...
│   └── wp1_2/                   # 渗透测试智能体
│       └── ...
├── tools/                       # LangGraph 工具定义
│   └── ...
└── utils/                       # 公共工具
    └── ...
data/                            # 运行时数据（gitignore）
├── attack_pool/                 # STIX 2.1 JSON 文件
├── test_scripts/                # 测试脚本
├── vuln_reports/                # 漏洞报告
└── logs/                        # 运行日志
```

---

### 阶段 1：WP1-1 情报采集智能体（完整实现）

按照 Mermaid 图 (`02_Intelligence-Collection-Module.mmd`) 的架构，内部是 **Supervisor 模式**：

| 步骤 | Agent | 详情 |
|------|-------|------|
| 1.1 | **Intel Supervisor** | LangGraph Supervisor 节点。职责：分析 `attack_pool/` 的 OWASP LLM Top 10 覆盖率，决定优先采集方向，将任务分派给下属 Agent，接收标准化结果反馈后决定是否继续采集 |
| 1.2 | **Web Crawler Agent** | 工具：`httpx` + `BeautifulSoup`。数据源：CVE/NVD API（`services.nvd.nist.gov`）、GitHub Security Advisories API、HuggingFace 安全公告。输出原始 JSON 数据 |
| 1.3 | **Paper Analyzer Agent** | 工具：arXiv API 搜索 + PDF 下载 + LLM 摘要提取。从安全论文中提取攻击方法、PoC 思路、防御建议 |
| 1.4 | **Dark Web Agent** | 初始实现：模拟数据源 + Telegram Bot API 采集（如果有 API key）。暗网爬取作为 placeholder，日后扩展 |
| 1.5 | **Standardizer Agent** | 将原始情报标准化为 STIX 2.1 兼容的 `AttackEntry` schema，执行去重（基于 payload 相似度检测），标注受影响的 AI BOM 组件，写入 `attack_pool/` |
| 1.6 | **LangGraph 图组装** | 将以上 Agent 组装为完整的 LangGraph StateGraph，定义状态流转：Supervisor → [Crawler/Paper/DarkWeb] → Standardizer → Supervisor（反馈循环） |
| 1.7 | **覆盖率统计工具** | 实现 OWASP LLM Top 10 覆盖率计算函数，供 Supervisor 决策使用 |

---

### 阶段 2：WP1-2 渗透测试智能体（完整实现）

按照 Mermaid 图 (`03_Red-team-Orchestrator.mmd`) 的架构，同样是 **Supervisor 模式**：

| 步骤 | Agent | 详情 |
|------|-------|------|
| 2.1 | **Red Team Orchestrator** | LangGraph Supervisor 节点。职责：从 `attack_pool/` 按策略选择攻击条目，分派给专家 Agent 生成脚本，追踪 OWASP Top 10 覆盖率 |
| 2.2 | **Prompt Injection Agent** | 读取 `attack_pool/` 中 `category=prompt_injection` 的条目，使用 LLM + payload 模板库生成直接/间接注入攻击脚本（Python 脚本 + 语料库） |
| 2.3 | **Jailbreak Agent** | 生成越狱攻击脚本：DAN 系列、角色扮演、编码绕过（Base64/ROT13）、token 走私等变种 |
| 2.4 | **Info Leakage Agent** | 生成信息泄露探测脚本：系统提示词提取、训练数据泄露、RAG 数据源泄露 |
| 2.5 | **Multimodal Attack Agent** | 生成多模态攻击脚本：图像对抗样本（需 PIL/numpy）、跨模态注入（图像中嵌入文本指令） |
| 2.6 | **Judge Agent** | 评估 Agent（图中的评估节点）：对生成的攻击脚本进行质量评估、预估 CVSS 评分、生成修复建议，输出为 `VulnReport` |
| 2.7 | **LangGraph 图组装** | 组装为 StateGraph：Orchestrator → [PIA/JA/ILA/MAA] → Judge → 写入 `test_scripts/` + `vuln_reports/` |
| 2.8 | **变异引擎** | 实现 payload 变异工具：同义词替换、编码变换、格式重排等，提高攻击多样性 |

---

### 阶段 3：Pipeline 编排 & API 层

| 步骤 | 内容 | 详情 |
|------|------|------|
| 3.1 | **Pipeline 主控** | 实现顶层 pipeline：WP1-1 采集完成 → 事件触发 → WP1-2 开始生成脚本。使用文件系统事件或简单的状态文件做协调 |
| 3.2 | **FastAPI 后端** | 基于已有的 FastAPI（google-adk 依赖已引入），暴露 REST API：查询 attack_pool、vuln_reports、pipeline 状态、手动触发运行等 |
| 3.3 | **前端对接** | 将 `web/src/services/api.ts` 从 mock 数据切换为真实 API 调用 |
| 3.4 | **CLI 入口** | 完善 `main.py`，支持命令行运行各子系统（如 `python main.py run-wp1-1`） |

---

### 阶段 4：测试 & 质量保证

| 步骤 | 内容 |
|------|------|
| 4.1 | 单元测试：Pydantic 模型验证、知识库 CRUD、各 Agent 的工具函数 |
| 4.2 | 集成测试：端到端 pipeline 测试（WP1-1 → WP1-2 数据流转） |
| 4.3 | Mock LLM 测试：使用固定响应测试 Agent 逻辑，不消耗 API 额度 |

---

### 建议的实施顺序

```
阶段 0 (基础设施) ──→ 阶段 1 (WP1-1) ──┐
                  └──→ 阶段 2 (WP1-2) ──┤──→ 阶段 3 (Pipeline + API) ──→ 阶段 4 (测试)
                                         │
                  (WP1-1 & WP1-2 可并行)  ┘
```

阶段 0 是前置依赖，必须先完成。阶段 1 和阶段 2 共享知识库接口，可以并行开发。阶段 3 依赖前两者完成。

---

你觉得这个计划如何？有几点想确认：

**Tool: question**

**Input:**
```json
{
  "questions": [
    {
      "header": "LLM 提供商偏好",
      "options": [
        {
          "label": "Google Gemini 为主",
          "description": "使用 langchain-google-genai，适配 GOOGLE_API_KEY"
        },
        {
          "label": "OpenAI GPT 为主",
          "description": "使用 langchain-openai，适配 OPENAI_API_KEY"
        },
        {
          "label": "两者都支持，可切换",
          "description": "配置文件控制使用哪个 LLM，两者都实现适配器"
        }
      ],
      "question": "智能体调用 LLM 时，优先使用哪个模型提供商？"
    },
    {
      "header": "开始实施？",
      "options": [
        {
          "label": "从阶段 0 开始实施",
          "description": "计划确认，立即开始搭建项目基础设施"
        },
        {
          "label": "需要调整计划",
          "description": "我有修改意见，先讨论再实施"
        },
        {
          "label": "只要计划，暂不实施",
          "description": "先保存计划，后续再开始写代码"
        }
      ],
      "question": "确认计划后，是否立即开始实施？"
    }
  ]
}
```

**Output:**
```
User has answered your questions: "智能体调用 LLM 时，优先使用哪个模型提供商？"="以OpenAI GPT以及兼容OpenAI API格式的供应商为主", "确认计划后，是否立即开始实施？"="只要计划，暂不实施". You can now continue with the user's answers in mind.
```

---

## Assistant (Plan · claude-opus-4.6 · 78.9s)

好的，计划已确认。以下是最终版的完整实施计划，已纳入你的所有偏好。

---

## 最终实施计划

**技术决策汇总：**
- 框架：**LangGraph**（编排）+ **LangChain**（LLM 集成）
- LLM：**OpenAI GPT 为主**（兼容 OpenAI API 格式的供应商），通过配置切换
- 知识库：**文件系统 + JSON**
- 范围：**WP1-1 + WP1-2 完整实现**（并行推进）
- 暂不实施，先确定计划

---

### 阶段 0：项目基础设施搭建

**0.1 Python 包结构**

```
saads/                           # 主包
├── __init__.py
├── config.py                    # 环境变量加载 + LLM 工厂（默认 OpenAI，支持任何兼容 OpenAI API 的供应商）
├── models/                      # Pydantic v2 数据模型（镜像前端 TypeScript 类型）
│   ├── __init__.py
│   ├── attack.py                # AttackEntry, AttackSource, AttackTemplate, MitreMapping, AttackMetadata
│   ├── vuln_report.py           # VulnReport, TargetApplication, Vulnerability, AttackVector, Remediation
│   ├── labeled_sample.py        # LabeledSample, ConversationTurn, Features, NetworkTrace
│   └── trained_model.py         # TrainedModel, ModelMetrics
├── knowledge_base/              # 文件系统 + JSON 知识库抽象层
│   ├── __init__.py
│   ├── base.py                  # BaseKnowledgeStore（接口：list/get/put/delete/query）
│   ├── attack_pool_store.py     # AttackPoolStore（attack_pool/ 目录 CRUD + 覆盖率统计）
│   ├── test_scripts_store.py    # TestScriptsStore（test_scripts/ 目录 CRUD）
│   └── vuln_reports_store.py    # VulnReportsStore（vuln_reports/ 目录 CRUD）
├── agents/
│   ├── __init__.py
│   ├── wp1_1/                   # 情报采集智能体
│   │   ├── __init__.py
│   │   ├── graph.py             # LangGraph StateGraph 组装（总入口）
│   │   ├── state.py             # 状态定义（IntelState）
│   │   ├── supervisor.py        # Intel Supervisor 节点
│   │   ├── web_crawler.py       # Web Crawler Agent
│   │   ├── paper_analyzer.py    # Paper Analyzer Agent
│   │   ├── dark_web.py          # Dark Web Agent（初期为 mock/placeholder）
│   │   └── standardizer.py      # Standardizer Agent
│   └── wp1_2/                   # 渗透测试智能体
│       ├── __init__.py
│       ├── graph.py             # LangGraph StateGraph 组装
│       ├── state.py             # 状态定义（RedTeamState）
│       ├── orchestrator.py      # Red Team Orchestrator 节点
│       ├── prompt_injection.py  # Prompt Injection Agent
│       ├── jailbreak.py         # Jailbreak Agent
│       ├── info_leakage.py      # Info Leakage Agent
│       ├── multimodal.py        # Multimodal Attack Agent
│       ├── judge.py             # Judge Agent（评估 + CVSS 评分）
│       └── mutation_engine.py   # Payload 变异引擎
├── tools/                       # LangGraph @tool 定义
│   ├── __init__.py
│   ├── web_tools.py             # HTTP 请求、网页解析
│   ├── api_tools.py             # NVD API、GitHub API、arXiv API 封装
│   ├── file_tools.py            # 知识库读写工具
│   └── llm_tools.py             # LLM 调用辅助工具
└── utils/
    ├── __init__.py
    ├── logging.py               # 统一日志
    └── owasp_taxonomy.py        # OWASP LLM Top 10 分类常量 + 覆盖率计算

data/                            # 运行时数据目录（加入 .gitignore）
├── attack_pool/                 # STIX 2.1 兼容 JSON（每条情报一个文件）
├── test_scripts/                # 生成的测试脚本（按攻击类型分子目录）
│   ├── prompt_injection/
│   ├── jailbreak/
│   ├── info_leakage/
│   └── multimodal/
├── vuln_reports/                # 漏洞报告 JSON
├── bom_knowledge/               # AI BOM 通用组件知识库
└── logs/                        # 运行日志

tests/                           # 测试
├── test_models/
├── test_knowledge_base/
├── test_agents/
│   ├── test_wp1_1/
│   └── test_wp1_2/
└── conftest.py
```

**0.2 补充 Python 依赖（添加到 `pyproject.toml`）**

```
langgraph >= 0.2.0          # Agent 编排框架
httpx >= 0.27.0             # 异步 HTTP 客户端（爬虫用）
beautifulsoup4 >= 4.12.0    # HTML 解析
pydantic >= 2.0.0           # 数据模型验证
fastapi >= 0.115.0          # REST API（后续阶段）
uvicorn >= 0.30.0           # ASGI 服务器
pytest >= 8.0.0             # 测试框架
pytest-asyncio >= 0.24.0    # 异步测试
```

**0.3 配置管理 (`saads/config.py`)**

- 从 `.env` 加载 `OPENAI_API_KEY`、`OPENAI_BASE_URL`（兼容第三方供应商）、`OPENAI_MODEL`（默认 `gpt-4o`）
- LLM 工厂函数：`get_llm() -> ChatOpenAI`，支持通过环境变量切换 base_url 和 model
- 全局路径配置：`DATA_DIR`、`ATTACK_POOL_DIR`、`TEST_SCRIPTS_DIR` 等

**0.4 Pydantic 数据模型**

严格镜像 `web/src/types/index.ts` 的 229 行类型定义，确保：
- 字段名、类型、枚举值完全一致
- 添加 `model_config = ConfigDict(populate_by_name=True)` 支持 JSON 序列化
- 所有模型实现 `.to_json()` 和 `.from_json()` 便捷方法

**0.5 知识库抽象层**

`BaseKnowledgeStore` 接口：
```python
class BaseKnowledgeStore(ABC):
    def list_all() -> list[T]
    def get_by_id(id: str) -> T | None
    def put(item: T) -> None          # 写入/更新
    def delete(id: str) -> bool
    def query(filters: dict) -> list[T]  # 简单过滤查询
    def count_by_field(field: str) -> dict[str, int]  # 分组统计
```

---

### 阶段 1：WP1-1 情报采集智能体

**1.1 LangGraph 状态定义 (`state.py`)**

```python
class IntelState(TypedDict):
    messages: Annotated[list, add_messages]
    collection_strategy: dict          # Supervisor 的采集策略
    raw_intel: list[dict]              # 各 Crawler 的原始输出
    standardized_entries: list[AttackEntry]  # 标准化后的条目
    coverage_report: dict              # OWASP Top 10 覆盖率
    iteration: int                     # 当前迭代轮次
    should_continue: bool              # 是否继续采集
```

**1.2 Intel Supervisor (`supervisor.py`)**

- 读取当前 `attack_pool/` 的 OWASP LLM Top 10 覆盖率
- 识别覆盖率最低的类别，生成采集策略（指定数据源 + 关键词 + 目标数量）
- 决定分派哪些子 Agent 执行
- 接收标准化结果后评估覆盖率改进，决定是否继续迭代

**1.3 Web Crawler Agent (`web_crawler.py`)**

工具实现：
| 工具 | 数据源 | 技术 |
|------|--------|------|
| `search_nvd` | NVD API (services.nvd.nist.gov) | httpx + NVD REST API，搜索 AI/ML 相关 CVE |
| `search_github_advisories` | GitHub Security Advisories | GitHub GraphQL API，过滤 AI 框架漏洞 |
| `search_huggingface` | HuggingFace 安全公告 | httpx + HTML 解析 |
| `crawl_security_blog` | 知名安全博客（如 OWASP blog） | httpx + BeautifulSoup |

Agent 逻辑：根据 Supervisor 策略选择对应工具，返回原始 JSON 列表。

**1.4 Paper Analyzer Agent (`paper_analyzer.py`)**

工具实现：
| 工具 | 功能 |
|------|------|
| `search_arxiv` | arXiv API 搜索 AI security 相关论文 |
| `extract_paper_summary` | LLM 调用：从论文摘要/全文提取攻击方法、PoC 思路、适用模型 |

Agent 逻辑：搜索论文 → LLM 提取结构化信息 → 输出原始情报。

**1.5 Dark Web Agent (`dark_web.py`)**

初始实现为 **placeholder**：
- 提供 `search_telegram`（如果配置了 Telegram Bot API key）
- 提供 `mock_dark_web_intel` 作为模拟数据源
- 预留接口供后续扩展真实暗网爬取

**1.6 Standardizer Agent (`standardizer.py`)**

工具实现：
| 工具 | 功能 |
|------|------|
| `standardize_to_stix` | LLM 调用：将原始情报转为 STIX 2.1 兼容的 AttackEntry JSON |
| `check_duplicate` | 基于 attack_id + payload 相似度去重 |
| `tag_ai_bom` | LLM 调用：标注受影响的 AI BOM 组件（模型名称、框架、版本） |
| `write_to_attack_pool` | 写入 `data/attack_pool/` 目录 |

**1.7 LangGraph 图组装 (`graph.py`)**

```
START → supervisor → route_to_agents → {web_crawler, paper_analyzer, dark_web} → standardizer → supervisor (loop)
                                                                                                        ↓
                                                                                                  should_continue=False → END
```

- Supervisor 是条件路由节点，根据策略决定激活哪些子 Agent
- 子 Agent 并行执行后汇聚到 Standardizer
- Standardizer 完成后回到 Supervisor 评估覆盖率，决定是否继续

---

### 阶段 2：WP1-2 渗透测试智能体

**2.1 LangGraph 状态定义 (`state.py`)**

```python
class RedTeamState(TypedDict):
    messages: Annotated[list, add_messages]
    selected_attacks: list[AttackEntry]  # Orchestrator 选中的攻击条目
    attack_assignment: dict              # 攻击分派（哪个 Agent 处理哪些）
    generated_scripts: list[dict]        # 各 Agent 生成的脚本
    evaluation_results: list[VulnReport] # Judge 评估结果
    coverage_report: dict                # OWASP Top 10 攻击覆盖率
    iteration: int
```

**2.2 Red Team Orchestrator (`orchestrator.py`)**

- 从 `attack_pool/` 读取攻击条目，按策略选择（优先覆盖率低的类别、高危条目）
- 根据 `category` 字段分派给对应专家 Agent
- 追踪 OWASP LLM Top 10 的攻击覆盖率

**2.3 Prompt Injection Agent (`prompt_injection.py`)**

生成脚本类型：
- 直接注入（Ignore previous instructions...）
- 间接注入（通过外部数据源注入）
- 上下文窗口溢出
- 指令覆盖

工具：`generate_injection_script` — LLM 基于 AttackEntry 的 payload_template + mutation_hints 生成可执行 Python 脚本

**2.4 Jailbreak Agent (`jailbreak.py`)**

生成脚本类型：
- DAN (Do Anything Now) 系列变种
- 角色扮演越狱
- 编码绕过（Base64、ROT13、Unicode）
- Token 走私 / 分词器攻击

工具：`generate_jailbreak_script` + `mutate_jailbreak_payload`（变异引擎）

**2.5 Info Leakage Agent (`info_leakage.py`)**

生成脚本类型：
- 系统提示词提取（"Repeat your instructions verbatim"）
- 训练数据泄露探测
- RAG 数据源泄露 / 配置信息泄露

工具：`generate_leakage_probe`

**2.6 Multimodal Attack Agent (`multimodal.py`)**

生成脚本类型：
- 图像中嵌入隐藏文本指令（对抗样本）
- 音频攻击（如果适用）
- 跨模态注入（image + text 组合攻击）

工具：`generate_adversarial_image`（需 PIL/numpy）、`generate_cross_modal_script`

**2.7 Judge Agent (`judge.py`)**

- 评估每个生成脚本的质量（是否有效、是否可执行、逻辑完整性）
- 预估 CVSS 评分（基于攻击类型、影响范围、利用难度）
- 生成修复建议
- 输出 `VulnReport` 写入 `vuln_reports/`

**2.8 变异引擎 (`mutation_engine.py`)**

纯 Python 实现（非 LLM），提供确定性变异：
- `synonym_replace`: 同义词替换（"ignore" → "disregard/forget/overlook"）
- `encoding_transform`: Base64 / ROT13 / Unicode 编码
- `format_rearrange`: markdown/HTML/代码块包裹
- `language_switch`: 中英文/小语种切换
- `token_split`: 跨 token 边界拆分关键词

**2.9 LangGraph 图组装 (`graph.py`)**

```
START → orchestrator → route_to_agents → {prompt_injection, jailbreak, info_leakage, multimodal} → judge → orchestrator (loop)
                                                                                                                    ↓
                                                                                                         coverage_sufficient → END
```

---

### 阶段 3：Pipeline 编排 & API 层

**3.1 顶层 Pipeline (`saads/pipeline.py`)**

简单的事件驱动协调：
1. 运行 WP1-1 → 检查 `attack_pool/` 是否有新增条目
2. 如有新增 → 触发 WP1-2 处理新条目
3. 记录 pipeline 状态到 `data/pipeline_status.json`

**3.2 FastAPI 后端 (`saads/api/`)**

端点设计：
| 方法 | 路径 | 功能 |
|------|------|------|
| GET | `/api/attack-pool` | 查询攻击池（支持分页/过滤） |
| GET | `/api/attack-pool/stats` | 攻击池统计（覆盖率等） |
| GET | `/api/vuln-reports` | 查询漏洞报告 |
| GET | `/api/vuln-reports/stats` | 漏洞报告统计 |
| GET | `/api/test-scripts` | 查询测试脚本 |
| GET | `/api/pipeline/status` | Pipeline 运行状态 |
| POST | `/api/pipeline/run` | 手动触发 pipeline |
| POST | `/api/wp1-1/run` | 单独运行情报采集 |
| POST | `/api/wp1-2/run` | 单独运行渗透测试 |

**3.3 前端对接**

修改 `web/src/services/api.ts`，将 mock 数据替换为真实 HTTP 调用。

**3.4 CLI 入口 (`main.py`)**

```bash
python main.py run-all              # 运行完整 pipeline
python main.py run-wp1-1            # 只运行情报采集
python main.py run-wp1-2            # 只运行渗透测试
python main.py stats                # 打印覆盖率统计
python main.py serve                # 启动 FastAPI 服务器
```

---

### 阶段 4：测试 & 质量保证

| 测试类型 | 范围 |
|----------|------|
| 模型验证测试 | Pydantic 模型的序列化/反序列化、边界值 |
| 知识库测试 | CRUD 操作、去重、查询、并发读写 |
| 工具单元测试 | 各 API 工具的请求/响应解析（使用 httpx mock） |
| Agent 逻辑测试 | 使用 Mock LLM 测试各 Agent 的决策逻辑 |
| 集成测试 | WP1-1 → WP1-2 数据流转端到端 |
| 变异引擎测试 | 各变异策略的输出验证 |

---

这就是完整的实施计划。当你准备好开始编码时，告诉我从哪个阶段/步骤开始，我会立即实施。

---

