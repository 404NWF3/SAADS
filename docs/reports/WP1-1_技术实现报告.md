# WP1-1 情报采集智能体 — 技术实现报告

> 生成日期：2026-02-21  
> 基于代码路径：`saads/agents/wp1_1/`、`saads/tools/api_tools.py`、`saads/models/attack.py`

---

## 一、智能体设计框架

### 1.1 整体架构：迭代式 Supervisor 图

WP1-1 采用 **LangGraph `StateGraph`** 构建，以 **Supervisor + 并行 Fan-out** 模式驱动迭代收集。整个图有一个明确的循环：

```
START
  │
  ▼
[supervisor_plan]          ← 分析现有情报覆盖缺口，生成本轮采集策略
  │ (并行 fan-out)
  ├──► [web_crawler]       ← 爬取公开结构化数据源（9 类来源）
  ├──► [paper_analyzer]    ← arXiv 学术论文 + LLM 摘要抽取
  └──► [dark_web]          ← 暗网 / Telegram 情报（当前为 mock）
  │ (fan-in，raw_intel 由 operator.add 自动合并)
  ▼
[standardizer]             ← LLM 归一化 → Pydantic 验证 → 写入磁盘
  ▼
[supervisor_eval]          ← 重新计算覆盖率，决定是否继续
  │
  ├──"continue"──► [supervisor_plan]   (最多 3 轮)
  └──"end"──────► END
```

**并行安全性**：`IntelState.raw_intel` 和 `standardized_entries` 字段使用 `operator.add` 作为 LangGraph reducer，三个收集器节点并发返回的列表自动拼接，无竞争条件。

### 1.2 节点职责

| 节点 | 文件 | 角色 |
|------|------|------|
| `supervisor_plan_node` | `supervisor.py` | 读取攻击池 → OWASP 覆盖率分析 → 生成 `collection_strategy` |
| `web_crawler_node` | `web_crawler.py` | 按策略调用最多 9 类数据源的 `_impl` 函数 |
| `paper_analyzer_node` | `paper_analyzer.py` | arXiv 搜索 + `gpt-4o-mini` 相关性评分与字段抽取 |
| `dark_web_node` | `dark_web.py` | 返回 14 条覆盖全部 6 类别的 mock 数据（Phase 2 预留 Telegram） |
| `standardizer_node` | `standardizer.py` | 去重 → LLM → `AttackEntry.model_validate()` → `AttackPoolStore.put()` |
| `supervisor_eval_node` | `supervisor.py` | 重新计算覆盖率，判断三个停止条件 |

### 1.3 迭代终止条件（三选一）

1. `iteration >= 3`（硬性上限）
2. OWASP 覆盖率 `>= 60%`（目标阈值）
3. `iteration >= 2` 且本轮未新增任何条目（进度停滞）

---

## 二、技术栈

### 2.1 核心框架

| 层次 | 技术 | 版本 | 用途 |
|------|------|------|------|
| 图执行引擎 | LangGraph | 1.0.7 | `StateGraph`、节点/边/条件路由、并行 fan-out |
| LLM 集成 | LangChain / langchain-openai | 1.2.8 / 1.1.7 | `ChatOpenAI`、`@tool` 装饰器、`HumanMessage` |
| 数据验证 | Pydantic v2 | 2.12.5 | `BaseModel`、`model_validate`、`model_dump_json` |
| HTTP 客户端 | httpx | 0.28.1 | 同步 `httpx.Client`（所有 API 调用） |
| HTML 解析 | BeautifulSoup4 | 4.12.0 | 博客/RSS HTML 解析 |
| 环境配置 | python-dotenv | 1.2.1 | `.env` 加载 |
| REST API | FastAPI + uvicorn | 0.128.2 / 0.40.0 | （当前 WP1-1 暂未使用，系统级预留） |

### 2.2 LLM 配置

| 函数 | 模型默认值 | temperature | 用于 |
|------|-----------|------------|------|
| `get_llm()` | `gpt-4o` | 0.1 | 系统级高质量任务（WP1-1 暂未直接调用） |
| `get_fast_llm()` | `gpt-4o-mini` | 0.0 | `paper_analyzer`（相关性抽取）、`standardizer`（归一化） |

两者均通过 `@lru_cache(maxsize=1)` 实现单例，`OPENAI_BASE_URL` 支持任意 OpenAI-compatible 接口（Azure、Ollama、LM Studio 等）。

### 2.3 数据源 API 技术细节

| # | 来源 | 接入方式 | 认证 | 备注 |
|---|------|----------|------|------|
| 1 | NVD | REST GET | 可选 `NVD_API_KEY` | CVSS v3.1/v3.0/v2 多版本兼容；403 自动重试 3 次 |
| 2 | GitHub Advisories | GraphQL POST | 必须 `GITHUB_TOKEN` | 双策略：按包名查 / 按关键词过滤；26 个 AI 包白名单 |
| 3 | arXiv | Atom XML GET | 无 | 手动 `urllib.parse.urlencode` 防双重编码；429 指数退避重试（6/12/24 s） |
| 4 | Reddit | RSS Atom GET | 无 | 规避 2023 后 JSON API 返回 403 的问题；自定义 `User-Agent` |
| 5 | HackerNews | Algolia REST GET | 无 | `hn.algolia.com/api/v1/search` |
| 6 | Exploit-DB | N/A | N/A | 占位符（JS 渲染页面无法直接爬取） |
| 7 | HuggingFace | REST GET（两端点） | 可选 `HF_TOKEN` | 模型 API + Daily Papers API 合并结果 |
| 8 | VirusTotal | REST GET v2 | 必须 `VIRUSTOTAL_API_KEY` | 当前 web_crawler 传入占位符，未实质查询 |
| 9 | AlienVault OTX | REST GET | 必须 `ALIENVAULT_API_KEY` | Pulse 搜索接口 |
| 10 | 安全博客 | HTTP + CSS selector | 无 | 6 个博客：OWASP、PortSwigger、Google Security、MSRC、OpenAI Research、NIST AI RMF |
| 11 | Dark Web (mock) | 本地硬编码 | N/A | 14 条覆盖 6 类别；Phase 2 预留 `telethon` + Tor 代理 |

---

## 三、数据模型设计

### 3.1 核心数据模型（STIX 2.1 兼容，Pydantic v2）

```
AttackEntry
├── attack_id: str                    # ATK-{2字母前缀}-{MD5[:6]}，确定性生成，用于去重
├── category: Literal[6 个类别]        # prompt_injection | jailbreak | info_leakage
│                                     # multimodal | dos | agent_hijack
├── subcategory: str
├── stix_type: str                    # default: "attack-pattern"
├── source: AttackSource
│   ├── type: Literal[13 个来源类型]
│   ├── url: str
│   ├── crawl_time: str               # ISO 8601
│   └── confidence: Literal["high","medium","low"]
├── attack_template: AttackTemplate
│   ├── name: str
│   ├── description: str
│   ├── payload_template: str
│   ├── variables: dict[str, str]
│   ├── modality: Literal["text","image","audio"]
│   └── mutation_hints: list[str]
├── mitre_mapping: MitreMapping
│   ├── tactic: str                   # e.g., "Initial Access"
│   └── technique: str               # e.g., "LLM Attack"
├── metadata: AttackMetadata
│   ├── severity_estimate: Literal["critical","high","medium","low"]
│   ├── target_type: list[str]
│   ├── defense_bypass: list[str]
│   ├── effectiveness: float | None
│   └── last_tested: str | None
└── status: Literal["active","tested","deprecated"]
```

### 3.2 共享状态模型（LangGraph TypedDict）

```python
class IntelState(TypedDict):
    messages:             Annotated[list, add_messages]          # 节点间消息
    collection_strategy:  dict                                   # Supervisor 生成的采集策略
    raw_intel:            Annotated[list[dict], operator.add]   # 并行合并的原始情报
    standardized_entries: Annotated[list[AttackEntry], operator.add]
    coverage_report:      dict                                   # OWASP 覆盖率报告
    iteration:            int
    should_continue:      bool
```

### 3.3 存储层

**`BaseKnowledgeStore[T]`** 抽象基类，策略：

- 每条记录对应一个 JSON 文件：`data/attack_pool/{ATK-PI-xxxxxx}.json`
- 读：`glob *.json` → `model_validate`；写：`model_dump_json(indent=2)`
- 支持：`list_all()`、`get_by_id()`、`put()`、`delete()`、`exists()`、`count()`、`query(**filters)`（支持点分路径，如 `source__type="nvd"`）、`count_by_field()`

**`AttackPoolStore`** 继承上述基类，额外提供：
- `get_by_category()`、`get_active()`
- `category_distribution()`、`severity_distribution()`、`source_distribution()`

### 3.4 OWASP 分类法

`owasp_taxonomy.py` 定义 OWASP LLM Top 10（2025 版），6 个内部攻击类别到 OWASP 条目的映射如下：

| 内部类别 | 覆盖的 OWASP 条目 |
|---------|-----------------|
| `prompt_injection` | LLM01、LLM05 |
| `info_leakage` | LLM02、LLM07 |
| `jailbreak` | LLM09 |
| `dos` | LLM10 |
| `agent_hijack` | LLM05、LLM06 |
| `multimodal` | 无直接映射 |

**注意**：LLM03（供应链）、LLM04（数据/模型投毒）、LLM08（向量/嵌入弱点）无对应内部类别，理论最大覆盖率为 **70%（7/10）**，而非 100%。

---

## 四、与设计文档的差异分析

本节对比现有实现与 `README.md`（架构设计）及 `docs/plan/项目业务.md`（业务功能描述）中的设想。

### 4.1 数据来源覆盖情况

| 设计文档要求 | 实现状态 | 说明 |
|------------|---------|------|
| CVE / NVD | ✅ 已实现 | `_search_nvd_impl`，含 CVSS 多版本兼容 |
| MITRE ATT&CK | ❌ 未实现 | 仅在输出中有 `mitre_mapping` 字段，无专用采集工具；无对 `attack.mitre.org` 的爬取 |
| GitHub Security Advisories | ✅ 已实现 | GraphQL 双策略查询 |
| HuggingFace | ✅ 已实现 | 模型 API + Daily Papers |
| arXiv | ✅ 已实现 | 含编码修复和 429 退避重试 |
| 暗网论坛 | ⚠️ Mock 阶段 | 14 条硬编码数据；Tor 代理 / Telegram telethon 集成为 Phase 2 占位符 |
| Telegram 群组 | ⚠️ 占位符 | `search_telegram()` 函数存在但立即返回空列表 |
| VirusTotal API | ⚠️ 部分实现 | `_query_virustotal_impl` 逻辑完整；但 `web_crawler.py` 中传入的是静态占位 URL，未进行真实查询 |
| AlienVault OTX | ✅ 已实现 | 完整的 Pulse 搜索 |
| Recorded Future | ❌ 未实现 | `项目业务.md` 提及，代码中无对应工具 |
| 安全博客 / RSS 源 | ✅ 已实现 | 6 个博客（CSS selector 提取） |
| Reddit | ✅ 已实现 | RSS Atom XML |
| HackerNews | ✅ 已实现 | Algolia API |
| Exploit-DB | ⚠️ 占位符 | 仅返回指引 URL，无实质爬取 |
| 自定义情报源（RSS） | ❌ 未实现 | `项目业务.md` 要求"支持添加特定网站、RSS 源"，当前 blog 列表硬编码 |

### 4.2 智能分析能力

| 设计要求 | 实现状态 | 说明 |
|---------|---------|------|
| NLP 解析非结构化报告 | ✅ 已实现 | `standardizer_node` 用 LLM 完成非结构化 → 结构化转换 |
| 映射到 MITRE ATT&CK for AI | ⚠️ 形式映射 | `MitreMapping` 字段存在，但 LLM prompt 中的战术/技术由模型自由生成，未约束到 MITRE 官方 ID 和名称体系 |
| 威胁评级（CVSS） | ⚠️ 近似实现 | 使用 `severity_estimate`（critical/high/medium/low），并非真正的 CVSS 数值计算 |
| 关联分析 / 攻击者画像 | ❌ 未实现 | 设计要求"识别关联威胁，构建攻击者画像"，当前无图数据库或关联逻辑 |
| 本体 + 知识图谱 | ❌ 未实现 | `项目业务.md` 第 4 节"本体 + 知识图谱"为核心差异化技术，当前代码中无知识图谱 |
| 去重 | ✅ 已实现 | 双重去重：预提交的 title-based MD5 + LLM 生成后的 `attack_id` 检查 |
| 聚合分析（24h 趋势报告） | ❌ 未实现 | 设计要求定期聚合报告，当前无时间窗口分析逻辑 |
| 高等级威胁实时告警 | ❌ 未实现 | 代码中有日志输出，但无告警推送机制（Webhook、邮件等） |

### 4.3 输出格式与接口

| 设计要求 | 实现状态 | 说明 |
|---------|---------|------|
| STIX 2.1 兼容 JSON | ⚠️ 兼容性有限 | `AttackEntry` 有 `stix_type` 字段，但未按 STIX 规范包含 `spec_version`、`id`（UUID 格式）、`created`、`modified` 等必填字段，严格意义上不是合法 STIX 2.1 Bundle |
| RESTful API 供其他模块调用 | ❌ 未实现 | `项目业务.md` 明确要求"提供 RESTful API"，当前无 FastAPI 路由；WP1-1 通过 Python 函数调用和文件系统交换数据 |
| 可操作测试用例（供 WP1-2 消费） | ⚠️ 半实现 | `AttackTemplate.payload_template` 字段存在，但内容由 LLM 自由填充，未按 WP1-2 期望的格式化模板生成 |
| 分层存储管理 | ❌ 未实现 | 当前只有本地 JSON 文件（平面存储），设计要求"分层存储管理"（热/冷数据）和向量数据库 |
| 情报源配置界面 | ❌ 未实现 | 当前完全硬编码 |

### 4.4 架构层面

| 设计原则 | 实现状态 | 说明 |
|---------|---------|------|
| 通用层与用户层分离 | ✅ 符合 | WP1-1 完全独立运行，不依赖用户系统 |
| 通过中央知识库解耦 | ✅ 符合 | `AttackPoolStore`（文件系统）作为 WP1-1 与 WP1-2 的共享中间层 |
| 渐进式复杂度（文件 → 数据库） | ✅ 当前在第一阶段 | 已按规划使用文件系统 + JSON |
| Supervisor 架构 | ✅ 符合 | LangGraph Supervisor 图，与 README 设计一致 |
| PDF 解析（学术报告） | ❌ 未实现 | README Agent 说明中写有"PDF 解析"，当前 `paper_analyzer` 只读 arXiv 摘要，不下载/解析 PDF |
| AI BOM 标注 | ❌ 未实现 | 这是 README 中的核心输出之一——"标注受影响的 AI BOM 组件类型与版本"，当前 `AttackEntry` 中无 BOM 相关字段 |

---

## 五、客观优缺点分析

### 5.1 优点

**1. 架构设计清晰、可扩展**  
LangGraph `StateGraph` 的 Supervisor + 并行 Fan-out 模式结构清晰，节点职责单一。新增数据源只需在 `api_tools.py` 添加 `_impl` 函数并在 `web_crawler.py` 添加一个分支，不影响其他节点。

**2. 并行采集且状态合并安全**  
`operator.add` reducer 让三个收集器节点真正并行运行，无需加锁，这是 LangGraph 的正确用法。

**3. 迭代式覆盖驱动采集**  
Supervisor 不是简单地遍历来源，而是基于 OWASP 覆盖缺口**决策**本轮优先采集哪些类别，具有策略性。这比固定轮询的架构更智能。

**4. 双重去重机制**  
`attack_id` 由 `hashlib.md5(title)` 确定性生成，在 LLM 处理前后各做一次存在性检查，有效避免重复写入。

**5. 数据模型完整**  
`AttackEntry` 涵盖情报来源、攻击模板（含 payload）、MITRE 映射、CVSS 严重级别和防御建议，字段设计完整，为下游 WP1-2 消费提供了良好的数据结构基础。

**6. 工程实践规范**  
- 内部 `_impl` 函数与 LangChain `@tool` 分离，便于直接导入测试  
- 所有 LLM 实例使用 `@lru_cache` 单例，避免重复初始化  
- `BaseKnowledgeStore` 泛型基类支持未来快速扩展其他存储对象  
- 日志规范，模块级 logger

**7. 已处理实际 API 限制**  
针对真实 API 的工程细节处理到位：arXiv 429 退避重试、NVD 403 重试、GitHub GraphQL 双策略降级、Reddit 2023 年 JSON API 封禁的 RSS 绕过。

**8. 多 LLM 提供商兼容**  
`OPENAI_BASE_URL` 配置使系统可以无缝切换到 Azure OpenAI、本地 Ollama/LM Studio，不绑定单一供应商。

---

### 5.2 不足

**1. 暗网采集为纯 Mock，无实质采集能力**  
`dark_web.py` 的 14 条硬编码数据是当前系统"生存"的重要支撑（保证各类别都有条目），但完全没有真实情报价值。Telegram 和 Tor 集成停留在注释层面，时间投入不足。

**2. STIX 2.1 标准合规性不足**  
`AttackEntry` 声称"STIX 2.1 兼容"，但缺少 STIX 规范要求的必填字段（`spec_version: "2.1"`、UUID 格式的 `id`、`created`/`modified` 时间戳）。当前格式是自定义 JSON，无法被标准 STIX 工具（如 TAXII 服务器、MISP）直接消费。

**3. 无 AI BOM 关联标注**  
README 将"标注受影响的 AI BOM 组件类型与版本"列为 WP1-1 的核心输出，但当前 `AttackEntry` 模型中完全没有该字段。WP1-3 无法基于 BOM 匹配进行精准筛选。

**4. MITRE 映射精度低**  
`MitreMapping.tactic` 和 `technique` 由 LLM 自由生成，没有约束到 MITRE 官方枚举值。LLM 可能生成 `"LLM Attack"` 这样的自造技术名，与 MITRE ATT&CK for AI 框架完全对不上，导致分类不一致。

**5. 理论最大 OWASP 覆盖率为 70%**  
LLM03（供应链）、LLM04（数据投毒）、LLM08（向量/嵌入弱点）在分类法中无对应的内部攻击类别，这 3 个威胁永远无法被"覆盖"，60% 的目标阈值是可实现的，但上限被锁死在 70%，反映出内部类别体系与 OWASP Top 10 的对齐不完整。

**6. VirusTotal 和 Exploit-DB 为占位符**  
`_query_virustotal_impl` 逻辑存在，但 `web_crawler.py` 对 VirusTotal 的调用仅追加一条静态 placeholder 而非真实查询；`_search_exploitdb_impl` 直接返回指引文本。这两个来源在覆盖率统计中被计算在内，但实际上不提供任何数据。

**7. 无 RESTful API**  
设计文档明确要求 WP1-1 对外提供 REST API 供其他模块调用，当前系统仅通过 Python 函数调用和文件系统交换数据，不支持跨进程、跨语言的集成，与"通过中央知识库解耦"原则存在摩擦。

**8. 无向量化检索**  
系统目前使用文件系统平面存储和精确字段过滤（`BaseKnowledgeStore.query()`）。设计要求向量数据库（语义相似度搜索、去重），特别是情报去重依赖 MD5(title)，无法发现语义重复的情报条目（标题不同但内容相同）。

**9. 收集器执行为同步阻塞**  
`web_crawler_node` 和 `paper_analyzer_node` 内部都使用 `httpx.Client`（同步）而非 `httpx.AsyncClient`，函数本身标为 `async def` 但实际阻塞事件循环。在 IO 密集型的多关键词循环中，性能瓶颈明显，应改为 `asyncio.gather` + `httpx.AsyncClient`。

**10. LLM 调用缺乏成本控制**  
`paper_analyzer_node` 对每篇论文都调用一次 `gpt-4o-mini`，`standardizer_node` 对每条原始情报调用一次。在 `max_per_source=5`、3 个查询、3 个来源的场景下，单次运行可能产生 40-50 次 LLM 调用，缺乏批处理（batch inference）机制，成本不可控。

**11. Paper Analyzer 仅读摘要，不解析 PDF**  
README 中明确要求 Paper Analyzer 能够"PDF 解析"。当前实现只读取 arXiv 摘要（截断至 800 字符），对于描述 PoC 代码和具体攻击步骤的学术论文，摘要信息严重不足。

---

## 六、总结

WP1-1 当前实现完成了**核心架构骨架**：LangGraph Supervisor 图、多源数据采集工具链、Pydantic 数据模型和文件存储层已经可以端到端运行，具备产出结构化情报条目的基本能力。

主要差距集中在三个方向：

1. **数据质量**：暗网为 mock、Exploit-DB / VirusTotal 为占位符、MITRE 映射不标准，影响下游 WP1-2 的情报可用性。
2. **标准合规**：STIX 2.1 不完整、无 AI BOM 字段，限制了与外部生态（TAXII、MISP、WP1-3）的集成。
3. **工程成熟度**：同步 HTTP 阻塞、无批量 LLM 推理、无 REST API、无向量检索，是从 PoC 走向生产的主要技术债务。
